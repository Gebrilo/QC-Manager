[
  {
    "projectId": "b889ac76-d541-4e57-9d32-a3e83be87acd",
    "testId": "67aece30-23e9-4557-b3ff-a3035034d9dc",
    "userId": "941804c8-e021-70a6-419f-b9c34881b9f0",
    "title": "TC001-verify health check endpoint",
    "description": "Test the /api/health GET endpoint to ensure it returns a successful response indicating the service is running.",
    "code": "import requests\n\ndef test_verify_health_check_endpoint():\n    base_url = \"http://72.61.157.168\"\n    url = f\"{base_url}/api/health\"\n    headers = {\n        \"Accept\": \"application/json\"\n    }\n    try:\n        response = requests.get(url, headers=headers, timeout=30)\n        response.raise_for_status()\n        # Expecting JSON response indicating service status\n        data = response.json()\n        assert isinstance(data, dict), \"Response is not a JSON object\"\n        # Simple check for common health properties\n        assert \"status\" in data or \"health\" in data or \"uptime\" in data or \"message\" in data, \"Response does not contain expected health info\"\n    except requests.exceptions.RequestException as e:\n        assert False, f\"Request failed: {e}\"\n\ntest_verify_health_check_endpoint()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"<string>\", line 11, in test_verify_health_check_endpoint\n  File \"/var/task/requests/models.py\", line 1024, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 404 Client Error: Not Found for url: http://72.61.157.168/api/health\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 20, in <module>\n  File \"<string>\", line 18, in test_verify_health_check_endpoint\nAssertionError: Request failed: 404 Client Error: Not Found for url: http://72.61.157.168/api/health\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-31T12:17:54.618Z",
    "modified": "2026-01-31T12:18:30.451Z"
  },
  {
    "projectId": "b889ac76-d541-4e57-9d32-a3e83be87acd",
    "testId": "bec8669b-33dd-4cf3-b780-bfcd5b31c49d",
    "userId": "941804c8-e021-70a6-419f-b9c34881b9f0",
    "title": "TC002-validate dashboard metrics retrieval",
    "description": "Test the /api/dashboard GET endpoint to verify it returns accurate and timely aggregated metrics from the v_dashboard_metrics view within 3 seconds.",
    "code": "import requests\nimport time\n\nBASE_URL = \"http://72.61.157.168\"\nTIMEOUT = 30\n\ndef test_validate_dashboard_metrics_retrieval():\n    url = f\"{BASE_URL}/api/dashboard\"\n    try:\n        start_time = time.time()\n        response = requests.get(url, timeout=TIMEOUT)\n        elapsed_time = time.time() - start_time\n\n        # Validate response status code\n        assert response.status_code == 200, f\"Expected 200 OK but got {response.status_code}\"\n\n        # Validate the response time (within 3 seconds)\n        assert elapsed_time <= 3, f\"Response time exceeded 3 seconds: {elapsed_time:.2f}s\"\n\n        # Validate that response contains JSON data with expected keys\n        data = response.json()\n        assert isinstance(data, dict), \"Response JSON is not an object\"\n\n        # Basic checks for expected keys in the dashboard metrics view\n        # Since the schema isn't detailed, we confirm presence of typical metric keys if any\n        expected_keys = [\n            \"totalProjects\", \"openTasks\", \"completedTasks\",\n            \"resourceUtilization\", \"qualityGateStatus\", \"releaseReadiness\"\n        ]\n        # It's allowed that some keys may be missing if data doesn't exist yet, so check at least one key presence\n        assert any(key in data for key in expected_keys), \\\n            f\"Response JSON does not contain any expected dashboard metric keys from {expected_keys}\"\n\n    except requests.RequestException as e:\n        assert False, f\"Request to /api/dashboard failed: {e}\"\n    except ValueError:\n        assert False, \"Response is not valid JSON\"\n\ntest_validate_dashboard_metrics_retrieval()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 39, in <module>\n  File \"<string>\", line 15, in test_validate_dashboard_metrics_retrieval\nAssertionError: Expected 200 OK but got 404\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-31T12:17:54.623Z",
    "modified": "2026-01-31T12:18:31.360Z"
  },
  {
    "projectId": "b889ac76-d541-4e57-9d32-a3e83be87acd",
    "testId": "aa44aef0-e569-4cb0-96cc-f2f60494d9f4",
    "userId": "941804c8-e021-70a6-419f-b9c34881b9f0",
    "title": "TC003-test project creation and listing",
    "description": "Test the /api/projects POST and GET endpoints to ensure projects can be created with valid data and listed correctly, enforcing input validation and audit logging.",
    "code": "import requests\n\nBASE_URL = \"http://72.61.157.168:3001\"\nTIMEOUT = 30\n\ndef test_project_creation_and_listing():\n    project_endpoint = f\"{BASE_URL}/api/projects\"\n    headers = {\"Content-Type\": \"application/json\"}\n\n    new_project = {\n        \"name\": \"Test Project TC003\",\n        \"description\": \"Project created during TC003 automation test\",\n        \"status\": \"active\"\n    }\n\n    project_id = None\n\n    try:\n        # Create a new project with valid data\n        create_response = requests.post(\n            project_endpoint,\n            json=new_project,\n            headers=headers,\n            timeout=TIMEOUT,\n        )\n        assert create_response.status_code == 201 or create_response.status_code == 200, \\\n            f\"Expected 201 or 200 on project creation, got {create_response.status_code}\"\n        create_data = create_response.json()\n\n        # Validate the project creation response contains expected keys\n        assert \"id\" in create_data, \"Response JSON missing 'id'\"\n        assert create_data.get(\"name\") == new_project[\"name\"], \"Project name mismatch\"\n        assert create_data.get(\"description\") == new_project[\"description\"], \"Project description mismatch\"\n\n        project_id = create_data[\"id\"]\n\n        # List projects and verify the created project is in the listing\n        list_response = requests.get(project_endpoint, headers=headers, timeout=TIMEOUT)\n        assert list_response.status_code == 200, f\"Expected 200 on project listing, got {list_response.status_code}\"\n        projects = list_response.json()\n\n        # projects expected to be a list (enforce that)\n        assert isinstance(projects, list), \"Project listing response is not a list\"\n\n        # Find created project in the list\n        found_projects = [p for p in projects if p.get(\"id\") == project_id]\n        assert len(found_projects) == 1, \"Created project not found in project listing\"\n\n        found_project = found_projects[0]\n        assert found_project[\"name\"] == new_project[\"name\"], \"Listed project name mismatch\"\n        assert found_project[\"description\"] == new_project[\"description\"], \"Listed project description mismatch\"\n\n    finally:\n        if project_id:\n            # Clean up - delete the created project using soft delete (if API supports DELETE)\n            delete_response = requests.delete(f\"{project_endpoint}/{project_id}\", headers=headers, timeout=TIMEOUT)\n            # Accept 200 or 204 or 404 if already deleted\n            assert delete_response.status_code in [200, 204, 404], f\"Unexpected status code on project deletion: {delete_response.status_code}\"\n\ntest_project_creation_and_listing()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 60, in <module>\n  File \"<string>\", line 26, in test_project_creation_and_listing\nAssertionError: Expected 201 or 200 on project creation, got 500\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-31T12:17:54.628Z",
    "modified": "2026-01-31T12:20:26.284Z"
  },
  {
    "projectId": "b889ac76-d541-4e57-9d32-a3e83be87acd",
    "testId": "96c727f4-a520-4b51-a9d0-133f65a29561",
    "userId": "941804c8-e021-70a6-419f-b9c34881b9f0",
    "title": "TC004-test project update and soft deletion",
    "description": "Test the /api/projects/:id PATCH and DELETE endpoints to verify projects can be updated with valid status transitions and soft-deleted, with audit logs capturing before and after states.",
    "code": "import requests\n\nBASE_URL = \"http://72.61.157.168:3001\"\nTIMEOUT = 30\n\n\ndef test_project_update_and_soft_deletion():\n    project_url = f\"{BASE_URL}/api/projects\"\n    created_project_id = None\n\n    try:\n        # Step 1: Create a new project to update and delete\n        new_project_data = {\n            \"name\": \"Test Project for Update and Delete\",\n            \"description\": \"Project created for testing PATCH and DELETE endpoints\",\n            \"status\": \"active\"  # assuming 'active' is a valid initial status\n        }\n        response = requests.post(project_url, json=new_project_data, timeout=TIMEOUT)\n        assert response.status_code == 201, f\"Unexpected status code on project creation: {response.status_code}\"\n        created_project = response.json()\n        created_project_id = created_project.get(\"id\")\n        assert created_project_id is not None, \"Created project ID is None\"\n\n        # Step 2: Fetch the original project for audit (before update)\n        get_project_url = f\"{project_url}/{created_project_id}\"\n        before_update_resp = requests.get(get_project_url, timeout=TIMEOUT)\n        assert before_update_resp.status_code == 200, f\"Failed to get project before update: {before_update_resp.status_code}\"\n        before_update_data = before_update_resp.json()\n\n        # Step 3: Update the project with a valid status transition\n        # We assume from 'active' to 'completed' is valid\n        update_payload = {\"status\": \"completed\"}\n        patch_resp = requests.patch(get_project_url, json=update_payload, timeout=TIMEOUT)\n        assert patch_resp.status_code == 200, f\"Project update failed with status code: {patch_resp.status_code}\"\n        updated_project_data = patch_resp.json()\n        assert updated_project_data.get(\"status\") == \"completed\", \"Project status did not update correctly\"\n\n        # Step 4: Verify audit logs captured before and after states\n        # Since audit logs API or data is not specified, verify the project GET after update changed\n        after_update_resp = requests.get(get_project_url, timeout=TIMEOUT)\n        assert after_update_resp.status_code == 200, f\"Failed to get project after update: {after_update_resp.status_code}\"\n        after_update_data = after_update_resp.json()\n        assert after_update_data.get(\"status\") == \"completed\", \"Status after update does not match expected\"\n\n        # Step 5: Soft delete the project via DELETE endpoint\n        delete_resp = requests.delete(get_project_url, timeout=TIMEOUT)\n        assert delete_resp.status_code == 200, f\"Soft delete failed with status code: {delete_resp.status_code}\"\n\n        # Step 6: Verify project is soft deleted\n        # Assuming GET after delete returns 404 or a field indicating deleted\n        get_after_delete_resp = requests.get(get_project_url, timeout=TIMEOUT)\n        if get_after_delete_resp.status_code == 404:\n            # Resource not found means deleted successfully\n            pass\n        elif get_after_delete_resp.status_code == 200:\n            deleted_project = get_after_delete_resp.json()\n            # Check for a deleted/archived field (if any)\n            # Since PRD doesn't specify, assume a 'deleted' boolean field signals soft deletion\n            assert deleted_project.get(\"deleted\") is True, \"Project not marked as deleted after DELETE\"\n        else:\n            assert False, f\"Unexpected status code after delete: {get_after_delete_resp.status_code}\"\n\n    finally:\n        # Cleanup: Ensure the created project is deleted if still present\n        if created_project_id:\n            requests.delete(f\"{project_url}/{created_project_id}\", timeout=TIMEOUT)\n\n\ntest_project_update_and_soft_deletion()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 69, in <module>\n  File \"<string>\", line 19, in test_project_update_and_soft_deletion\nAssertionError: Unexpected status code on project creation: 500\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-31T12:17:54.633Z",
    "modified": "2026-01-31T12:20:28.124Z"
  },
  {
    "projectId": "b889ac76-d541-4e57-9d32-a3e83be87acd",
    "testId": "5da3fde1-76d3-44aa-8eee-1ba6fc665016",
    "userId": "941804c8-e021-70a6-419f-b9c34881b9f0",
    "title": "TC005-test task creation and listing",
    "description": "Test the /api/tasks POST and GET endpoints to ensure tasks can be created with proper resource allocation checks and listed with accurate status and assignment details.",
    "code": "import requests\nimport uuid\n\nBASE_URL = \"http://72.61.157.168:3001\"\nTIMEOUT = 30\nHEADERS = {\n    \"Content-Type\": \"application/json\"\n}\n\ndef test_task_creation_and_listing():\n    task_id = None\n    # Prepare a sample resource to assign (need at least one resource to be present)\n    resource_id = None\n    resource_created = False\n    try:\n        # Step 1: Ensure at least one resource exists or create one\n        resources_resp = requests.get(f\"{BASE_URL}/api/resources\", timeout=TIMEOUT)\n        assert resources_resp.status_code == 200, f\"Failed getting resources, status: {resources_resp.status_code}\"\n        resources = resources_resp.json()\n        if resources and isinstance(resources, list) and len(resources) > 0:\n            resource_id = resources[0].get(\"id\") or resources[0].get(\"resourceId\") or resources[0].get(\"_id\")\n        else:\n            # Create a new resource\n            resource_payload = {\n                \"name\": f\"Test Resource {uuid.uuid4()}\",\n                \"role\": \"tester\",\n                \"capacity\": 100\n            }\n            create_res_resp = requests.post(f\"{BASE_URL}/api/resources\", json=resource_payload, headers=HEADERS, timeout=TIMEOUT)\n            assert create_res_resp.status_code == 201, f\"Failed creating resource, status: {create_res_resp.status_code}, response: {create_res_resp.text}\"\n            resource_created = True\n            resource_resp_json = create_res_resp.json()\n            resource_id = resource_resp_json.get(\"id\") or resource_resp_json.get(\"_id\")\n        assert resource_id is not None, \"No resource ID available for assigning to task\"\n\n        # Step 2: Create a new task assigned to this resource, ensure payload is valid and realistic\n        task_payload = {\n            \"title\": f\"Test Task {uuid.uuid4()}\",\n            \"description\": \"Task created during automated test for creation and listing.\",\n            \"status\": \"pending\",  # assuming 'pending' is a valid initial status\n            \"assignedResourceId\": resource_id,\n            \"estimatedEffort\": 10  # hypothetical hours or points\n        }\n        create_task_resp = requests.post(f\"{BASE_URL}/api/tasks\", json=task_payload, headers=HEADERS, timeout=TIMEOUT)\n        assert create_task_resp.status_code == 201, f\"Task creation failed with status: {create_task_resp.status_code}, response: {create_task_resp.text}\"\n        task_resp_json = create_task_resp.json()\n        task_id = task_resp_json.get(\"id\") or task_resp_json.get(\"_id\")\n        assert task_id is not None, \"Created task does not have an ID\"\n\n        # Validate response contains expected keys and values\n        assert task_resp_json.get(\"title\") == task_payload[\"title\"]\n        assert task_resp_json.get(\"status\") == task_payload[\"status\"]\n        assert task_resp_json.get(\"assignedResourceId\") == resource_id\n\n        # Step 3: Get the list of tasks and verify the created task is listed with correct details\n        list_tasks_resp = requests.get(f\"{BASE_URL}/api/tasks\", timeout=TIMEOUT)\n        assert list_tasks_resp.status_code == 200, f\"Failed to list tasks, status: {list_tasks_resp.status_code}\"\n        tasks_list = list_tasks_resp.json()\n        assert isinstance(tasks_list, list), \"Tasks list response is not a list\"\n\n        # Find the created task in the list\n        matched_tasks = [t for t in tasks_list if (t.get(\"id\") == task_id or t.get(\"_id\") == task_id)]\n        assert len(matched_tasks) == 1, f\"Created task with ID {task_id} not found or duplicated in task list\"\n        matched_task = matched_tasks[0]\n\n        # Validate key fields in matched task\n        assert matched_task.get(\"title\") == task_payload[\"title\"]\n        assert matched_task.get(\"status\") == task_payload[\"status\"]\n        assert matched_task.get(\"assignedResourceId\") == resource_id\n    finally:\n        # Cleanup: Delete the created task and resource if applicable\n        if task_id:\n            requests.delete(f\"{BASE_URL}/api/tasks/{task_id}\", timeout=TIMEOUT)\n        if resource_created and resource_id:\n            requests.delete(f\"{BASE_URL}/api/resources/{resource_id}\", timeout=TIMEOUT)\n\n\ntest_task_creation_and_listing()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 78, in <module>\n  File \"<string>\", line 18, in test_task_creation_and_listing\nAssertionError: Failed getting resources, status: 500\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-31T12:17:54.637Z",
    "modified": "2026-01-31T12:20:28.249Z"
  },
  {
    "projectId": "b889ac76-d541-4e57-9d32-a3e83be87acd",
    "testId": "433b054b-6db2-4cbd-b51d-c64a03df7136",
    "userId": "941804c8-e021-70a6-419f-b9c34881b9f0",
    "title": "TC006-test task update and soft deletion",
    "description": "Test the /api/tasks/:id PATCH and DELETE endpoints to verify tasks can be updated with valid status transitions and soft-deleted, enforcing resource utilization limits and audit logging.",
    "code": "import requests\nimport time\n\nBASE_URL = \"http://72.61.157.168:3001\"\nTASKS_ENDPOINT = f\"{BASE_URL}/api/tasks\"\nTIMEOUT = 30\n\ndef test_task_update_and_soft_deletion():\n    # Create a new task first\n    create_payload = {\n        \"title\": \"Test Task for Update and Soft Deletion\",\n        \"description\": \"Task created for testing PATCH and DELETE endpoints\",\n        \"status\": \"pending\",  # assuming \"pending\" is a valid initial status\n        \"resource_id\": None  # updated field name to match expected API\n    }\n\n    task_id = None\n    try:\n        create_resp = requests.post(TASKS_ENDPOINT, json=create_payload, timeout=TIMEOUT)\n        assert create_resp.status_code == 201, f\"Task creation failed: {create_resp.text}\"\n        task_data = create_resp.json()\n        task_id = task_data.get(\"id\") or task_data.get(\"taskId\")\n        assert task_id is not None, \"Created task ID not returned\"\n\n        # Retrieve the created task to confirm creation\n        get_resp = requests.get(f\"{TASKS_ENDPOINT}/{task_id}\", timeout=TIMEOUT)\n        assert get_resp.status_code == 200, f\"Failed to retrieve created task: {get_resp.text}\"\n        task_before_update = get_resp.json()\n        assert task_before_update.get(\"status\") == \"pending\", \"Initial task status mismatch\"\n\n        # Update task status - valid status transition e.g. pending -> in_progress\n        patch_payload = {\n            \"status\": \"in_progress\"\n        }\n        patch_resp = requests.patch(f\"{TASKS_ENDPOINT}/{task_id}\", json=patch_payload, timeout=TIMEOUT)\n        assert patch_resp.status_code == 200, f\"Task update PATCH failed: {patch_resp.text}\"\n        updated_task = patch_resp.json()\n        assert updated_task.get(\"status\") == \"in_progress\", \"Task status not updated correctly\"\n\n        # Verify audit log captured - no direct API endpoint described, so verify status changed by refetch\n        verify_resp = requests.get(f\"{TASKS_ENDPOINT}/{task_id}\", timeout=TIMEOUT)\n        assert verify_resp.status_code == 200, \"Failed to fetch updated task after PATCH\"\n        verify_task = verify_resp.json()\n        assert verify_task.get(\"status\") == \"in_progress\", \"Task status incorrect after PATCH\"\n\n        # Soft delete the task - DELETE on /api/tasks/:id\n        delete_resp = requests.delete(f\"{TASKS_ENDPOINT}/{task_id}\", timeout=TIMEOUT)\n        assert delete_resp.status_code == 200, f\"Task DELETE failed: {delete_resp.text}\"\n\n        # Verify task is soft deleted - GET should either 404 or show deleted flag\n        get_after_delete_resp = requests.get(f\"{TASKS_ENDPOINT}/{task_id}\", timeout=TIMEOUT)\n        # Assumptions:\n        # - Either 404 Not Found for soft-deleted resources OR\n        # - Response contains deleted flag or status='deleted'\n        if get_after_delete_resp.status_code == 404:\n            pass  # acceptable soft deletion verification\n        elif get_after_delete_resp.status_code == 200:\n            task_after_delete = get_after_delete_resp.json()\n            # Check if status or deleted indicator present, assuming 'deleted' or 'status' = 'deleted'\n            deleted_flag = (task_after_delete.get(\"deleted\") is True) or (task_after_delete.get(\"status\") == \"deleted\")\n            assert deleted_flag, \"Task not marked as deleted after DELETE\"\n        else:\n            assert False, f\"Unexpected response after DELETE: {get_after_delete_resp.status_code} {get_after_delete_resp.text}\"\n\n        # Optional: Validate resource utilization limits not exceeded\n        # Since no direct endpoint or field, assume task update rejects invalid transitions or oversized utilization\n        # Test invalid status transition that should fail (e.g. in_progress -> pending)\n        invalid_patch_payload = {\n            \"status\": \"pending\"\n        }\n        invalid_patch_resp = requests.patch(f\"{TASKS_ENDPOINT}/{task_id}\", json=invalid_patch_payload, timeout=TIMEOUT)\n        assert invalid_patch_resp.status_code in (400, 422), \"Invalid status transition was not rejected\"\n\n    finally:\n        # Cleanup: Ensure task is deleted if it exists (hard delete for test environment safety if supported)\n        if task_id:\n            try:\n                requests.delete(f\"{TASKS_ENDPOINT}/{task_id}\", timeout=TIMEOUT)\n            except Exception:\n                pass\n\ntest_task_update_and_soft_deletion()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 82, in <module>\n  File \"<string>\", line 20, in test_task_update_and_soft_deletion\nAssertionError: Task creation failed: Proxy server error: connect ETIMEDOUT 72.61.157.168:3001\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-31T12:17:54.651Z",
    "modified": "2026-01-31T12:21:26.891Z"
  },
  {
    "projectId": "b889ac76-d541-4e57-9d32-a3e83be87acd",
    "testId": "058485cf-02c9-4789-9897-6217bf89762a",
    "userId": "941804c8-e021-70a6-419f-b9c34881b9f0",
    "title": "TC007-test resource creation and listing",
    "description": "Test the /api/resources POST and GET endpoints to ensure resources can be created with utilization metrics and listed correctly, supporting capacity monitoring.",
    "code": "import requests\n\nBASE_URL = \"http://72.61.157.168:3001\"\nTIMEOUT = 30\n\ndef test_resource_creation_and_listing():\n    resource_data = {\n        \"name\": \"Test Resource TC007\",\n        \"description\": \"Resource created for test case TC007\",\n        \"capacity\": 100,\n        \"utilization\": 50\n    }\n    resource_id = None\n    try:\n        # Create a new resource via POST /api/resources\n        post_response = requests.post(\n            f\"{BASE_URL}/api/resources\",\n            json=resource_data,\n            timeout=TIMEOUT\n        )\n        assert post_response.status_code == 201, f\"Expected status 201, got {post_response.status_code}\"\n        resp_json = post_response.json()\n        assert \"id\" in resp_json, \"Response JSON missing resource id\"\n        resource_id = resp_json[\"id\"]\n        assert resp_json.get(\"name\") == resource_data[\"name\"], \"Resource name mismatch\"\n        assert resp_json.get(\"capacity\") == resource_data[\"capacity\"], \"Resource capacity mismatch\"\n        assert resp_json.get(\"utilization\") == resource_data[\"utilization\"], \"Resource utilization mismatch\"\n\n        # List all resources via GET /api/resources and verify the created resource is listed\n        get_response = requests.get(\n            f\"{BASE_URL}/api/resources\",\n            timeout=TIMEOUT\n        )\n        assert get_response.status_code == 200, f\"Expected status 200, got {get_response.status_code}\"\n        resources = get_response.json()\n        assert isinstance(resources, list), \"Resources list response is not a list\"\n        found = False\n        for r in resources:\n            if r.get(\"id\") == resource_id:\n                found = True\n                assert r.get(\"name\") == resource_data[\"name\"], \"Listed resource name mismatch\"\n                assert r.get(\"capacity\") == resource_data[\"capacity\"], \"Listed resource capacity mismatch\"\n                assert r.get(\"utilization\") == resource_data[\"utilization\"], \"Listed resource utilization mismatch\"\n                # Check capacity monitoring logic: utilization should not exceed capacity\n                assert r[\"utilization\"] <= r[\"capacity\"], \"Utilization exceeds capacity\"\n                break\n        assert found, \"Created resource not found in resource listing\"\n    finally:\n        # Cleanup: delete the created resource if it exists\n        if resource_id:\n            del_response = requests.delete(\n                f\"{BASE_URL}/api/resources/{resource_id}\",\n                timeout=TIMEOUT\n            )\n            assert del_response.status_code in (200, 204), f\"Expected 200 or 204 on delete, got {del_response.status_code}\"\n\ntest_resource_creation_and_listing()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/urllib3/connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n               ^^^^^^^^^^^^^^^^^^^\n  File \"/var/task/urllib3/connectionpool.py\", line 534, in _make_request\n    response = conn.getresponse()\n               ^^^^^^^^^^^^^^^^^^\n  File \"/var/task/urllib3/connection.py\", line 565, in getresponse\n    httplib_response = super().getresponse()\n                       ^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/lang/lib/python3.12/http/client.py\", line 1430, in getresponse\n    response.begin()\n  File \"/var/lang/lib/python3.12/http/client.py\", line 331, in begin\n    version, status, reason = self._read_status()\n                              ^^^^^^^^^^^^^^^^^^^\n  File \"/var/lang/lib/python3.12/http/client.py\", line 292, in _read_status\n    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/lang/lib/python3.12/socket.py\", line 720, in readinto\n    return self._sock.recv_into(b)\n           ^^^^^^^^^^^^^^^^^^^^^^^\nConnectionResetError: [Errno 104] Connection reset by peer\n\nThe above exception was the direct cause of the following exception:\n\nurllib3.exceptions.ProxyError: ('Unable to connect to proxy', ConnectionResetError(104, 'Connection reset by peer'))\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/var/task/requests/adapters.py\", line 667, in send\n    resp = conn.urlopen(\n           ^^^^^^^^^^^^^\n  File \"/var/task/urllib3/connectionpool.py\", line 841, in urlopen\n    retries = retries.increment(\n              ^^^^^^^^^^^^^^^^^^\n  File \"/var/task/urllib3/util/retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='tun.testsprite.com', port=8080): Max retries exceeded with url: http://72.61.157.168:3001/api/resources (Caused by ProxyError('Unable to connect to proxy', ConnectionResetError(104, 'Connection reset by peer')))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 57, in <module>\n  File \"<string>\", line 16, in test_resource_creation_and_listing\n  File \"/var/task/requests/api.py\", line 115, in post\n    return request(\"post\", url, data=data, json=json, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/task/requests/api.py\", line 59, in request\n    return session.request(method=method, url=url, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/task/requests/sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/task/requests/sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/var/task/requests/adapters.py\", line 694, in send\n    raise ProxyError(e, request=request)\nrequests.exceptions.ProxyError: HTTPConnectionPool(host='tun.testsprite.com', port=8080): Max retries exceeded with url: http://72.61.157.168:3001/api/resources (Caused by ProxyError('Unable to connect to proxy', ConnectionResetError(104, 'Connection reset by peer')))\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-31T12:17:54.715Z",
    "modified": "2026-01-31T12:20:26.285Z"
  },
  {
    "projectId": "b889ac76-d541-4e57-9d32-a3e83be87acd",
    "testId": "699965c1-e1a5-4d35-b79e-493680ec2e28",
    "userId": "941804c8-e021-70a6-419f-b9c34881b9f0",
    "title": "TC008-test resource update and soft deletion",
    "description": "Test the /api/resources/:id PATCH and DELETE endpoints to verify resources can be updated and soft-deleted, with audit logs capturing changes and utilization updates.",
    "code": "import requests\n\nBASE_URL = \"http://72.61.157.168:3001\"\nHEADERS = {\"Content-Type\": \"application/json\"}\nTIMEOUT = 30\n\n\ndef test_resource_update_and_soft_deletion():\n    resource_data = {\n        \"name\": \"Test Resource for Update\",\n        \"role\": \"QA Engineer\",\n        \"capacity\": 100,\n        \"utilization\": 0\n    }\n\n    created_resource_id = None\n    try:\n        # Create a new resource first\n        create_resp = requests.post(\n            f\"{BASE_URL}/api/resources\",\n            json=resource_data,\n            headers=HEADERS,\n            timeout=TIMEOUT,\n        )\n        assert create_resp.status_code == 201, f\"Resource creation failed: {create_resp.text}\"\n        created_resource = create_resp.json()\n        created_resource_id = created_resource.get(\"id\")\n        assert created_resource_id is not None, \"Created resource ID is None\"\n\n        # Prepare patch data to update resource\n        update_data = {\n            \"role\": \"Senior QA Engineer\",\n            \"utilization\": 50\n        }\n\n        # Update the resource with PATCH\n        patch_resp = requests.patch(\n            f\"{BASE_URL}/api/resources/{created_resource_id}\",\n            json=update_data,\n            headers=HEADERS,\n            timeout=TIMEOUT,\n        )\n        assert patch_resp.status_code == 200, f\"Resource update failed: {patch_resp.text}\"\n        updated_resource = patch_resp.json()\n        # Check updated fields\n        assert updated_resource.get(\"role\") == \"Senior QA Engineer\", \"Role not updated correctly\"\n        assert updated_resource.get(\"utilization\") == 50, \"Utilization not updated correctly\"\n        # Assert audit logs exist in response if provided (optional)\n        assert \"auditLogs\" in updated_resource or True  # no error if no auditLogs returned\n\n        # Now soft-delete the resource with DELETE\n        delete_resp = requests.delete(\n            f\"{BASE_URL}/api/resources/{created_resource_id}\",\n            headers=HEADERS,\n            timeout=TIMEOUT,\n        )\n        assert delete_resp.status_code == 200, f\"Resource soft-deletion failed: {delete_resp.text}\"\n        deleted_resource = delete_resp.json()\n        # Confirm soft deletion, typically by a 'deleted' flag or similar\n        assert deleted_resource.get(\"deleted\") in [True, \"true\", 1], \"Resource not soft-deleted properly\"\n\n        # Optionally verify the resource is no longer returned in active lists\n        list_resp = requests.get(\n            f\"{BASE_URL}/api/resources\",\n            headers=HEADERS,\n            timeout=TIMEOUT,\n        )\n        assert list_resp.status_code == 200, f\"Failed to list resources: {list_resp.text}\"\n        resources = list_resp.json()\n        if isinstance(resources, list):\n            assert all(res.get(\"id\") != created_resource_id or res.get(\"deleted\") for res in resources), \\\n                \"Soft deleted resource still appears as active in resource list\"\n\n    finally:\n        if created_resource_id is not None:\n            # Cleanup: ensure resource is deleted (hard delete not documented, so try soft delete)\n            try:\n                requests.delete(\n                    f\"{BASE_URL}/api/resources/{created_resource_id}\",\n                    headers=HEADERS,\n                    timeout=TIMEOUT,\n                )\n            except Exception:\n                pass\n\n\ntest_resource_update_and_soft_deletion()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 87, in <module>\n  File \"<string>\", line 25, in test_resource_update_and_soft_deletion\nAssertionError: Resource creation failed: Proxy server error: connect ETIMEDOUT 72.61.157.168:3001\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-31T12:17:54.728Z",
    "modified": "2026-01-31T12:20:28.122Z"
  },
  {
    "projectId": "b889ac76-d541-4e57-9d32-a3e83be87acd",
    "testId": "d0ec2d08-84b2-48ae-8c7b-b6f05c2cec79",
    "userId": "941804c8-e021-70a6-419f-b9c34881b9f0",
    "title": "TC009-validate governance release readiness retrieval",
    "description": "Test the /api/governance/release-readiness GET endpoint to ensure it returns accurate release readiness status for all projects based on quality gates.",
    "code": "import requests\n\ndef test_validate_governance_release_readiness_retrieval():\n    base_url = \"http://72.61.157.168\"\n    url = f\"{base_url}/api/governance/release-readiness\"\n    headers = {\n        \"Accept\": \"application/json\"\n    }\n    timeout = 30\n\n    try:\n        response = requests.get(url, headers=headers, timeout=timeout)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        assert False, f\"Request to {url} failed: {e}\"\n\n    try:\n        data = response.json()\n    except ValueError:\n        assert False, \"Response content is not valid JSON\"\n\n    assert isinstance(data, list), \"Response should be a list of release readiness statuses\"\n\n    # Each item should contain at least project identifier and readiness status\n    for item in data:\n        assert isinstance(item, dict), \"Each item should be a dictionary\"\n        assert \"projectId\" in item or \"project_id\" in item, \"Each item should contain a project identifier\"\n        assert (\"readinessStatus\" in item or \"readiness_status\" in item), \"Each item should contain a readiness status\"\n\n    # Optionally check readiness status values if known (e.g., status string or boolean)\n    # But since no specific schema given, we just check presence and non-null\n    for item in data:\n        readiness = item.get(\"readinessStatus\") or item.get(\"readiness_status\")\n        assert readiness is not None, \"Readiness status should not be null\"\n\ntest_validate_governance_release_readiness_retrieval()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"<string>\", line 13, in test_validate_governance_release_readiness_retrieval\n  File \"/var/task/requests/models.py\", line 1024, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 404 Client Error: Not Found for url: http://72.61.157.168/api/governance/release-readiness\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 36, in <module>\n  File \"<string>\", line 15, in test_validate_governance_release_readiness_retrieval\nAssertionError: Request to http://72.61.157.168/api/governance/release-readiness failed: 404 Client Error: Not Found for url: http://72.61.157.168/api/governance/release-readiness\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-31T12:17:54.732Z",
    "modified": "2026-01-31T12:20:29.189Z"
  },
  {
    "projectId": "b889ac76-d541-4e57-9d32-a3e83be87acd",
    "testId": "77a5bdeb-cbc6-4120-9df8-e7e3cce3ba81",
    "userId": "941804c8-e021-70a6-419f-b9c34881b9f0",
    "title": "TC010-test quality gates configuration management",
    "description": "Test the /api/governance/gates/:projectId GET and /api/governance/gates POST endpoints to verify quality gates can be retrieved, created, and updated with correct validation and audit logging.",
    "code": "import requests\n\nBASE_URL = \"http://72.61.157.168:3001\"\nTIMEOUT = 30\nHEADERS = {\"Content-Type\": \"application/json\"}\n\ndef test_quality_gates_configuration_management():\n    # Step 1: Create a new project to associate with quality gates (needed to get projectId)\n    project_payload = {\n        \"name\": \"Test Project for Quality Gates\",\n        \"description\": \"Created for TC010 quality gates management test\"\n    }\n    created_project = None\n    created_gate = None\n\n    try:\n        # Create project\n        resp_project = requests.post(\n            f\"{BASE_URL}/api/projects\",\n            json=project_payload,\n            headers=HEADERS,\n            timeout=TIMEOUT,\n        )\n        assert resp_project.status_code == 201, f\"Expected 201, got {resp_project.status_code}\"\n        created_project = resp_project.json()\n        assert \"id\" in created_project, \"Created project response missing 'id'\"\n        project_id = created_project[\"id\"]\n\n        # Step 2: Initially GET quality gates for the new project (expect empty or default)\n        resp_get_gates_initial = requests.get(\n            f\"{BASE_URL}/api/governance/gates/{project_id}\",\n            headers=HEADERS,\n            timeout=TIMEOUT,\n        )\n        assert resp_get_gates_initial.status_code == 200, f\"GET gates returned {resp_get_gates_initial.status_code}\"\n        initial_gates = resp_get_gates_initial.json()\n        assert isinstance(initial_gates, dict), \"Initial gates response should be a dict\"\n\n        # Step 3: Create or update quality gates by POST\n        gate_payload = {\n            \"projectId\": project_id,\n            \"gates\": [\n                {\n                    \"name\": \"Code Coverage\",\n                    \"threshold\": 80,\n                    \"enabled\": True,\n                    \"description\": \"Minimum code coverage percentage\",\n                },\n                {\n                    \"name\": \"Static Analysis\",\n                    \"threshold\": 90,\n                    \"enabled\": True,\n                    \"description\": \"Static code analysis score threshold\",\n                }\n            ]\n        }\n        resp_post_gates = requests.post(\n            f\"{BASE_URL}/api/governance/gates\",\n            json=gate_payload,\n            headers=HEADERS,\n            timeout=TIMEOUT,\n        )\n        assert resp_post_gates.status_code in (200, 201), f\"POST gates returned {resp_post_gates.status_code}\"\n        created_gate = resp_post_gates.json()\n        assert \"projectId\" in created_gate and created_gate[\"projectId\"] == project_id, \"Gate response projectId mismatch\"\n        assert \"gates\" in created_gate and isinstance(created_gate[\"gates\"], list) and len(created_gate[\"gates\"]) > 0, \"Gates not returned or invalid\"\n\n        # Step 4: GET quality gates again to verify persistence and correctness\n        resp_get_gates_after = requests.get(\n            f\"{BASE_URL}/api/governance/gates/{project_id}\",\n            headers=HEADERS,\n            timeout=TIMEOUT,\n        )\n        assert resp_get_gates_after.status_code == 200, f\"GET gates after update returned {resp_get_gates_after.status_code}\"\n        gates_after = resp_get_gates_after.json()\n        assert \"gates\" in gates_after and isinstance(gates_after[\"gates\"], list) and len(gates_after[\"gates\"]) >= 2, \"Updated gates missing or incomplete\"\n        # Validate that the gates returned contain the expected gates by name and threshold\n        gate_names = {gate.get(\"name\"): gate for gate in gates_after[\"gates\"]}\n        for expected_gate in gate_payload[\"gates\"]:\n            assert expected_gate[\"name\"] in gate_names, f\"Expected gate '{expected_gate['name']}' not found in updated gates\"\n            g = gate_names[expected_gate[\"name\"]]\n            assert g.get(\"threshold\") == expected_gate[\"threshold\"], f\"Gate threshold mismatch for {expected_gate['name']}\"\n            assert g.get(\"enabled\") == expected_gate[\"enabled\"], f\"Gate enabled flag mismatch for {expected_gate['name']}\"\n\n        # Step 5: Validation - try creating/updating gates with invalid data and expect errors\n        invalid_payloads = [\n            {\"projectId\": project_id},  # missing 'gates'\n            {\"projectId\": project_id, \"gates\": \"not a list\"},  # invalid gates type\n            {\"projectId\": project_id, \"gates\": [{\"name\": \"\", \"threshold\": 50, \"enabled\": True}]},  # empty name\n            {\"projectId\": project_id, \"gates\": [{\"name\": \"GateX\", \"threshold\": -10, \"enabled\": True}]},  # negative threshold\n            {\"projectId\": project_id, \"gates\": [{\"name\": \"GateY\", \"threshold\": 101, \"enabled\": True}]},  # threshold > 100\n        ]\n\n        for invalid_payload in invalid_payloads:\n            resp_invalid = requests.post(\n                f\"{BASE_URL}/api/governance/gates\",\n                json=invalid_payload,\n                headers=HEADERS,\n                timeout=TIMEOUT,\n            )\n            assert resp_invalid.status_code >= 400, f\"Invalid payload accepted: {invalid_payload}\"\n\n    finally:\n        # Cleanup created gates: Although no endpoint to delete gates explicitly, assume updating with empty gates disables them\n        if created_gate and \"projectId\" in created_gate:\n            try:\n                requests.post(\n                    f\"{BASE_URL}/api/governance/gates\",\n                    json={\"projectId\": created_gate[\"projectId\"], \"gates\": []},\n                    headers=HEADERS,\n                    timeout=TIMEOUT,\n                )\n            except Exception:\n                pass\n\n        # Cleanup created project\n        if created_project:\n            try:\n                requests.delete(\n                    f\"{BASE_URL}/api/projects/{created_project['id']}\",\n                    headers=HEADERS,\n                    timeout=TIMEOUT,\n                )\n            except Exception:\n                pass\n\ntest_quality_gates_configuration_management()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 127, in <module>\n  File \"<string>\", line 24, in test_quality_gates_configuration_management\nAssertionError: Expected 201, got 500\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2026-01-31T12:17:54.738Z",
    "modified": "2026-01-31T12:21:28.425Z"
  }
]
